{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NILMTK Rapid Experimentation API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the use of NILMTK's ExperimentAPI - a  new  NILMTK  interface which  allows NILMTK users to focus on which experiments to run rather than on the code required to run such experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that handing over so much flexibility to the user does require the user to be somewhat familiar with the data set, but this part of the process is supported by NILMTK as data exploration is simple and well documented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets us start with a very simple experiment to demonstrate the use of the API for multiple appliances in a minimal use case. This experiment shows how the user can select the appliances in the dataset on which disaggregation is to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.api import API\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the required algorithms on which we wish to run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate import CO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we enter the values for the different parameters in the dictionary. Since we need multiple appliances, we enter the names of all the required appliances in the _'appliances'_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1 = {\n",
    "  'power': {'mains': ['apparent','active'],'appliance': ['apparent','active']},\n",
    "  'sample_rate': 60,\n",
    "  'appliances': ['air conditioner'],\n",
    "  'methods': {\"CO\":CO({})},\n",
    "  'train': {    \n",
    "    'datasets': {\n",
    "        'Dataport': {\n",
    "            'path': '/app/nilmtk-contrib/data/ukdale.h5',\n",
    "            'buildings': {\n",
    "                1: {\n",
    "                    'start_time': '2013-04-04',\n",
    "                    'end_time': '2013-04-06'\n",
    "                    }\n",
    "                }                \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "  'test': {\n",
    "    'datasets': {\n",
    "        'Dataport': {\n",
    "            'path': '/app/nilmtk-contrib/data/ukdale.h5',\n",
    "            'buildings': {\n",
    "                1: {\n",
    "                    'start_time': '2013-04-25',\n",
    "                    'end_time': '2013-04-26'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'metrics':['rmse']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example experimental setup, we have set the _sample rate_ at 60Hz and use Combinatorial Optimisation to \n",
    "disaggregate the required appliances from building 10 in the dataport dataset with the _RMSE_ metric to measure the accuracy. We also specify the dates for training and testing\n",
    "\n",
    "Next we provide this experiment dictionary as input to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Testing for all algorithms\n",
      "Loading data for  Dataport  dataset\n",
      "Dropping missing values\n",
      "Generating predictions for : CO\n",
      "...............CO disaggregate_chunk running.............\n",
      "Estimating power demand for 'microwave'"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2880) does not match length of index (1440)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m api_results_experiment_1 \u001b[38;5;241m=\u001b[39m \u001b[43mAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/api.py:46\u001b[0m, in \u001b[0;36mAPI.__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDROP_ALL_NANS \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP_ALL_NANS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msite_only \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_only\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/api.py:105\u001b[0m, in \u001b[0;36mAPI.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Testing for all algorithms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_jointly\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/api.py:274\u001b[0m, in \u001b[0;36mAPI.test_jointly\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_mains \u001b[38;5;241m=\u001b[39m [test_mains]\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoring_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dataset) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(building) \n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimezone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/api.py:323\u001b[0m, in \u001b[0;36mAPI.call_predict\u001b[0;34m(self, classifiers, timezone)\u001b[0m\n\u001b[1;32m    321\u001b[0m gt_overall\u001b[38;5;241m=\u001b[39m{}           \n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name,clf \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[0;32m--> 323\u001b[0m     gt_overall,pred_overall[name]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_mains\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_submeters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimezone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_overall\u001b[38;5;241m=\u001b[39mgt_overall\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_overall\u001b[38;5;241m=\u001b[39mpred_overall\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/api.py:373\u001b[0m, in \u001b[0;36mAPI.predict\u001b[0;34m(self, clf, test_elec, test_submeters, sample_period, timezone)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mGenerates predictions on the test dataset using the specified classifier.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# \"ac_type\" varies according to the dataset used. \u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Make sure to use the correct ac_type before using the default parameters in this code.   \u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m pred_list \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisaggregate_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_elec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# It might not have time stamps sometimes due to neural nets\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# It has the readings for all the appliances\u001b[39;00m\n\u001b[1;32m    378\u001b[0m concat_pred_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(pred_list,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nilmtk-4.0.0-py3.9.egg/nilmtk/disaggregate/combinatorial_optimisation.py:163\u001b[0m, in \u001b[0;36mCO.disaggregate_chunk\u001b[0;34m(self, mains)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimating power demand for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m           \u001b[38;5;241m.\u001b[39mformat(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappliance_name\u001b[39m\u001b[38;5;124m'\u001b[39m]),end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     predicted_power \u001b[38;5;241m=\u001b[39m state_combinations[\n\u001b[1;32m    162\u001b[0m         indices_of_state_combinations, i]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m--> 163\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicted_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     appliance_powers_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappliance_name\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m column\n\u001b[1;32m    167\u001b[0m appliance_powers \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    168\u001b[0m     appliance_powers_dict, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:461\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    459\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n\u001b[0;32m--> 461\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (2880) does not match length of index (1440)"
     ]
    }
   ],
   "source": [
    "api_results_experiment_1 = API(experiment1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the prediction vs. truth graphs in the above cell. The accuracy metrics can be accessed using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_keys = api_results_experiment_1.errors_keys\n",
    "errors = api_results_experiment_1.errors\n",
    "for i in range(len(errors)):\n",
    "    print (errors_keys[i])\n",
    "    print (errors[i])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a trivial experiment that only scratches the surface of the true potential of this API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next experiment we will run an incrementally more complex version of the above experiment. Here we will use multiple models to disaggregate the appliance readings with the models having their own sets of parameters which can be set by the users within the experimental dictionary in order to fine tune experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import the required algorithms for the next experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate import FHMM_EXACT, Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment2 = {\n",
    "  'power': {'mains': ['apparent','active'],'appliance': ['apparent','active']},\n",
    "  'sample_rate': 60,\n",
    "  'appliances': ['fridge','air conditioner', 'microwave'],\n",
    "  'methods': {\"Mean\":Mean({}),\"FHMM_EXACT\":FHMM_EXACT({'num_of_states':2}), \"CombinatorialOptimisation\":CO({})},\n",
    "  'train': {    \n",
    "    'datasets': {\n",
    "        'Dataport': {\n",
    "            'path': 'data/dataport.hdf5',\n",
    "            'buildings': {\n",
    "                10: {\n",
    "                    'start_time': '2015-04-04',\n",
    "                    'end_time': '2015-04-06'\n",
    "                    }\n",
    "                }                \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "  'test': {\n",
    "    'datasets': {\n",
    "        'Datport': {\n",
    "            'path': 'data/dataport.hdf5',\n",
    "            'buildings': {\n",
    "                10: {\n",
    "                    'start_time': '2015-04-25',\n",
    "                    'end_time': '2015-04-26'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'metrics':['mae', 'rmse']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_results_experiment_2 = API(experiment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results_experiment_2.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_keys = api_results_experiment_2.errors_keys\n",
    "errors = api_results_experiment_2.errors\n",
    "for i in range(len(errors)):\n",
    "    print (errors_keys[i])\n",
    "    print (errors[i])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API makes running experiments extremely quick and efficient, with the emphasis on creating finely tuned reproducible experiments where model and parameter performances can be easily evaluated at a glance.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next iteration of this experiment, we introduce more parameters _chunksize_, _DROP_ALL_NANS_ and _artificial_aggregate_ and add another disaggregation algorithm (_Hart85_). We also train and test data from multiple buildings of the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import the Hart algorithm for the next experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate import Hart85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment3 = {\n",
    "  'power': {'mains': ['apparent','active'],'appliance': ['apparent','active']},\n",
    "  'sample_rate': 60,\n",
    "  'appliances': ['fridge','air conditioner','electric furnace','washing machine'],\n",
    "  'artificial_aggregate': True,\n",
    "  'chunksize': 20000,\n",
    "  'DROP_ALL_NANS': False,\n",
    "  'methods': {\"Mean\":Mean({}),\"Hart85\":Hart85({}), \"FHMM_EXACT\":FHMM_EXACT({'num_of_states':2}), \"CO\":CO({})},\n",
    "  'train': {    \n",
    "    'datasets': {\n",
    "      'Dataport': {\n",
    "        'path': 'data/dataport.hdf5',\n",
    "        'buildings': {\n",
    "          54: {\n",
    "            'start_time': '2015-01-28',\n",
    "            'end_time': '2015-02-12'\n",
    "          },\n",
    "          56: {\n",
    "            'start_time': '2015-01-28',\n",
    "            'end_time': '2015-02-12'\n",
    "          },\n",
    "          57: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-14'\n",
    "          },\n",
    "                }                \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "  'test': {\n",
    "    'datasets': {\n",
    "      'Datport': {\n",
    "        'path': 'data/dataport.hdf5',\n",
    "        'buildings': {\n",
    "          94: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          },\n",
    "          103: {\n",
    "            'start_time': '2014-01-26',\n",
    "            'end_time': '2014-02-03'\n",
    "          },\n",
    "          113: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          },\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "        'metrics':['mae', 'rmse']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_results_experiment_3 = API(experiment3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_keys = api_results_experiment_3.errors_keys\n",
    "errors = api_results_experiment_3.errors\n",
    "for i in range(len(errors)):\n",
    "    print (errors_keys[i])\n",
    "    print (errors[i])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the above experiment are presented for every chunk per building in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following experiment, we demonstrate how to run experiments across datasets, which was previously not possible. The important thing to pay attention to is that such datasets can only be trained and tested together as long as they have common appliances in homes with common _ac_types_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment4 = {\n",
    "  'power': {'mains': ['apparent','active'],'appliance': ['apparent','active']},\n",
    "  'sample_rate': 60,\n",
    "  'appliances': ['washing machine','fridge'],\n",
    "  'artificial_aggregate': True,\n",
    "  'chunksize': 20000,\n",
    "  'DROP_ALL_NANS': False,\n",
    "  'methods': {\"Mean\":Mean({}),\"Hart85\":Hart85({}), \"FHMM_EXACT\":FHMM_EXACT({'num_of_states':2}), 'CO':CO({})},   \n",
    "  'train': {\n",
    "    'datasets': {\n",
    "      'UKDALE': {\n",
    "        'path': 'C:/Users/Hp/Desktop/nilmtk-contrib/ukdale.h5',\n",
    "        'buildings': {\n",
    "              1: {\n",
    "                'start_time': '2017-01-05',\n",
    "                'end_time': '2017-03-05'\n",
    "              },          \n",
    "            }\n",
    "          },        \n",
    "        }\n",
    "      },    \n",
    "  'test': {\n",
    "    'datasets': {\n",
    "      'DRED': {\n",
    "        'path': 'C:/Users/Hp/Desktop/nilmtk-contrib/dred.h5',\n",
    "        'buildings': {\n",
    "              1: {\n",
    "                    'start_time': '2015-09-21',\n",
    "                    'end_time': '2015-10-01'\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      'REDD': {\n",
    "        'path': 'C:/Users/Hp/Desktop/nilmtk-contrib/redd.h5',\n",
    "        'buildings': {\n",
    "              1: {\n",
    "                    'start_time': '2011-04-17',\n",
    "                    'end_time': '2011-04-27'\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "        'metrics':['mae', 'rmse']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results_experiment_4 = API(experiment4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_keys = api_results_experiment_4.errors_keys\n",
    "errors = api_results_experiment_4.errors\n",
    "for i in range(len(errors)):\n",
    "    print (errors_keys[i])\n",
    "    print (errors[i])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the above experiments, any user can set up other experiments very quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
